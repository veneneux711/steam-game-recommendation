{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import knn_improvements as knn_imp  # Import các hàm cải tiến\n",
    "reviews = pd.read_csv(\"final_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_details = pd.read_csv(\"final_games.csv\")\n",
    "print(games_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_games = pd.read_csv(\"your_games.csv\")\n",
    "print(your_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_games_id = your_games[your_games['review'] == 0.5]['gameID'].tolist()\n",
    "\n",
    "print(interested_games_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_games_id = set(your_games[your_games['review'] == -1]['gameID'])\n",
    "\n",
    "print(bad_games_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_games = pd.read_csv(\"fav_games.csv\")\n",
    "print(fav_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_games_id = sorted(list(your_games['gameID'].unique()))\n",
    "print(my_games_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_played_games_id = [id for id in my_games_id if id not in interested_games_id]\n",
    "print(not_played_games_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Assuming 'reviews' is your DataFrame containing reviews data\n",
    "\n",
    "# Step 1: Get the list of game IDs from my_games_id\n",
    "num_games = len(my_games_id)\n",
    "\n",
    "# CẢI TIẾN: Sử dụng optimal threshold thay vì công thức cố định\n",
    "threshold = knn_imp.calculate_optimal_threshold(my_games_id, reviews, percentile=25)\n",
    "print(\"Optimal threshold:\", threshold)\n",
    "\n",
    "# Step 2: Count the number of reviews per user for the specified game IDs\n",
    "user_review_counts = reviews[reviews['app_id'].isin(set(my_games_id))].groupby('user_id')['app_id'].size()\n",
    "\n",
    "# Step 3: Identify users who have reviewed at least threshold number of games\n",
    "relevant_users = user_review_counts[user_review_counts >= threshold].index\n",
    "\n",
    "# Step 4: Filter reviews for these relevant users\n",
    "filtered_reviews = reviews[reviews['user_id'].isin(relevant_users)]\n",
    "filtered_reviews.loc[:,'is_recommended'] = filtered_reviews['is_recommended'].map({True: 1, False: -1})\n",
    "# Display or process the filtered reviews\n",
    "print(filtered_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique users and games in filtered reviews\n",
    "num_unique_users = filtered_reviews['user_id'].nunique()\n",
    "num_unique_games = filtered_reviews['app_id'].nunique()\n",
    "\n",
    "# Display the counts\n",
    "print(f\"Number of unique users in filtered reviews: {num_unique_users}\")\n",
    "print(f\"Number of unique games in filtered reviews: {num_unique_games}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Step 2: Get unique user IDs and sorted list of unique app IDs\n",
    "user_id_list = sorted(filtered_reviews['user_id'].unique())\n",
    "games_id_reviews = sorted(filtered_reviews['app_id'].unique())\n",
    "\n",
    "# Step 3: Create dictionaries for index mapping\n",
    "user_to_index = {user_id: idx for idx, user_id in enumerate(user_id_list)}\n",
    "app_to_index = {app_id: idx for idx, app_id in enumerate(games_id_reviews)}\n",
    "\n",
    "# Step 4: Use vectorized operations to map user and app IDs to indices\n",
    "row_indices = np.array([user_to_index[user_id] for user_id in filtered_reviews['user_id']])\n",
    "col_indices = np.array([app_to_index[app_id] for app_id in filtered_reviews['app_id']])\n",
    "data = np.array(filtered_reviews['is_recommended'])\n",
    "\n",
    "user_vector_sparse = csr_matrix((data, (row_indices, col_indices)), shape=(num_unique_users, num_unique_games))\n",
    "\n",
    "print(user_vector_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_list = list(range(num_unique_users))\n",
    "print(user_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary for my_vector\n",
    "my_vector = {}\n",
    "\n",
    "# Assuming your_games is a pandas DataFrame and games_id_reviews is a list of game IDs\n",
    "for game_id in my_games_id:\n",
    "    if game_id not in games_id_reviews:\n",
    "        continue\n",
    "    review_value = your_games.loc[your_games['gameID'] == game_id, 'review'].values[0]\n",
    "    my_vector[games_id_reviews.index(game_id)] = review_value\n",
    "\n",
    "# Convert my_vector to a sparse vector using scipy.sparse.csr_matrix\n",
    "my_vector = csr_matrix((list(my_vector.values()), ([0]*len(my_vector), list(my_vector.keys()))), shape=(1, len(games_id_reviews)))\n",
    "\n",
    "\n",
    "print(my_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fav_games['gameID'] to a set for faster membership testing\n",
    "fav_games_set = set(fav_games['gameID'])\n",
    "\n",
    "# CẢI TIẾN: Sử dụng hàm tính weights cải tiến (sửa bug và đơn giản hóa)\n",
    "# Giảm multipliers để tránh weights quá lớn/nhỏ\n",
    "weights = knn_imp.calculate_weights_improved(\n",
    "    user_vector_sparse, \n",
    "    games_id_reviews, \n",
    "    fav_games_set, \n",
    "    bad_games_id,\n",
    "    fav_weight_multiplier=1.5,  # Giảm từ 2.0 xuống 1.5 để tránh weights quá lớn\n",
    "    bad_weight_multiplier=0.7   # Tăng từ 0.5 lên 0.7 để giảm penalty\n",
    ")\n",
    "\n",
    "print(\"Weights calculated with improvements:\")\n",
    "print(f\"Min: {weights.min():.4f}, Max: {weights.max():.4f}, Mean: {weights.mean():.4f}\")\n",
    "print(f\"Total users: {len(weights)}\")\n",
    "print(weights[:20])  # Chỉ in 20 đầu tiên để dễ xem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "series = pd.Series(weights)\n",
    "\n",
    "# Count occurrences\n",
    "counts = series.value_counts()\n",
    "\n",
    "# Print counts\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "def getDistanceList(my_vector):\n",
    "    # Calculate cosine distances using cosine_distances from sklearn\n",
    "    distances = cosine_distances(user_vector_sparse, my_vector).flatten()\n",
    "    \n",
    "    # Create list of tuples (index, distance, user_vector_sparse[i])\n",
    "    distance_list = [(i, distances[i], user_vector_sparse[i]) for i in range(user_vector_sparse.shape[0])]\n",
    "    \n",
    "    # Sort by distance\n",
    "    distance_list = sorted(distance_list, key=lambda x: x[1])\n",
    "    \n",
    "    return distance_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKnnVector(my_vector, k=None, use_adaptive_k=False):\n",
    "    \"\"\"\n",
    "    CẢI TIẾN: Hàm getKnnVector - giữ gần với code gốc để đảm bảo relevance scores đúng\n",
    "    Adaptive K tắt mặc định, có thể bật nếu cần\n",
    "    \"\"\"\n",
    "    distance_list = getDistanceList(my_vector)\n",
    "\n",
    "    # CẢI TIẾN: Adaptive K selection (TẮT mặc định)\n",
    "    if use_adaptive_k and k is None:\n",
    "        k = knn_imp.calculate_optimal_k(distance_list, min_k=5, max_k=50)\n",
    "        print(f\"Using adaptive K: {k}\")\n",
    "    elif k is None:\n",
    "        k = min(30, len(distance_list))  # Giữ như code gốc\n",
    "    \n",
    "    actual_k = min(k, len(distance_list))\n",
    "    \n",
    "    if actual_k == 0:\n",
    "        return np.zeros(my_vector.shape[1])  # Trả về vector rỗng nếu không tìm thấy ai\n",
    "\n",
    "    # Thay k bằng actual_k trong vòng lặp\n",
    "    indices = np.array([distance_list[i][0] for i in range(actual_k)])\n",
    "    distances = np.array([distance_list[i][1] for i in range(actual_k)])\n",
    "    \n",
    "    user_vectors = user_vector_sparse[indices]\n",
    "\n",
    "    # GIỮ NGUYÊN CÁCH TÍNH NHƯ CODE GỐC để đảm bảo relevance scores đúng\n",
    "    # Compute weights (cần xử lý trường hợp distance = 0 để tránh chia cho 0)\n",
    "    safe_distances = distances + 1e-9 \n",
    "    weights_factors = weights[indices] / safe_distances\n",
    "\n",
    "    # Multiply user vectors by weights\n",
    "    weighted_vectors = user_vectors.multiply(weights_factors[:, None])\n",
    "\n",
    "    # Sum the weighted vectors\n",
    "    vector = weighted_vectors.sum(axis=0).A1\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMesure(rcm,vector):\n",
    "    recommended_game_ids = [game[0] for game in rcm]\n",
    "    recommended_game_index = [games_id_reviews.index(id) for id in recommended_game_ids]\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    vector = vector.toarray().flatten()\n",
    "    for i in range(len(games_id_reviews)):\n",
    "        if vector[i] > 0:\n",
    "            if i in recommended_game_index:\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        elif vector[i] < 0:\n",
    "            if i in recommended_game_index:\n",
    "                false_positive += 1\n",
    "            else:\n",
    "                true_negative += 1\n",
    "    print(\"True positive:\",true_positive)\n",
    "    print(\"True negative:\",true_negative)\n",
    "    print(\"False negative:\",false_negative)\n",
    "    print(\"False positive\",false_positive)\n",
    "    all_predictions = true_positive + false_positive + true_negative + false_negative\n",
    "    accuracy = (true_positive + true_negative) * 100 / all_predictions\n",
    "    if true_positive + false_positive == 0:\n",
    "        precision = accuracy\n",
    "    else:\n",
    "        precision = true_positive * 100 / (true_positive + false_positive)\n",
    "    if (true_positive + false_negative) == 0:\n",
    "        recall = accuracy\n",
    "    else:\n",
    "        recall = true_positive * 100 / (true_positive + false_negative)\n",
    "    return np.array([accuracy,precision,recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def split_vector(vector):\n",
    "    # Convert vector to CSR format if not already in CSR format\n",
    "    if not isinstance(vector, csr_matrix):\n",
    "        vector = csr_matrix(vector)\n",
    "    \n",
    "    # Extract data, indices, and indptr from the CSR matrix\n",
    "    data = vector.data\n",
    "    indices = vector.indices\n",
    "    indptr = vector.indptr\n",
    "    \n",
    "    # Identify positive (>0) and negative (<0) indices\n",
    "    positive_indices = [i for i, val in enumerate(data) if val > 0]\n",
    "    negative_indices = [i for i, val in enumerate(data) if val < 0]\n",
    "    \n",
    "    # Calculate counts of positive and negative elements\n",
    "    positive_count = len(positive_indices)\n",
    "    negative_count = len(negative_indices)\n",
    "    \n",
    "    # Determine split counts based on the desired ratio (80% and 20%)\n",
    "    first_subvector_positive_count = int(0.8 * positive_count)\n",
    "    first_subvector_negative_count = int(0.8 * negative_count)\n",
    "    \n",
    "    # Shuffle positive and negative indices randomly\n",
    "    np.random.shuffle(positive_indices)\n",
    "    np.random.shuffle(negative_indices)\n",
    "    \n",
    "    # Initialize data structures for subvectors\n",
    "    first_subvector_data = np.zeros_like(data)\n",
    "    second_subvector_data = np.zeros_like(data)\n",
    "    \n",
    "    # Assign values to subvectors based on indices\n",
    "    for i in positive_indices[:first_subvector_positive_count]:\n",
    "        first_subvector_data[i] = data[i]\n",
    "    for i in positive_indices[first_subvector_positive_count:]:\n",
    "        second_subvector_data[i] = data[i]\n",
    "    \n",
    "    for i in negative_indices[:first_subvector_negative_count]:\n",
    "        first_subvector_data[i] = data[i]\n",
    "    for i in negative_indices[first_subvector_negative_count:]:\n",
    "        second_subvector_data[i] = data[i]\n",
    "    \n",
    "    # Create CSR matrices for subvectors\n",
    "    first_subvector = csr_matrix((first_subvector_data, indices, indptr), shape=vector.shape)\n",
    "    second_subvector = csr_matrix((second_subvector_data, indices, indptr), shape=vector.shape)\n",
    "    \n",
    "    return first_subvector, second_subvector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendedGameId(k=None, test=False, use_adaptive_k=True, apply_popularity_penalty=False, popularity_penalty_factor=0.05):\n",
    "    \"\"\"\n",
    "    CẢI TIẾN: Hàm getRecommendedGameId với adaptive K\n",
    "    Lưu ý: Tắt popularity penalty mặc định vì có thể làm giảm chất lượng\n",
    "    \"\"\"\n",
    "    print(\"k =\", k if k else \"adaptive\")\n",
    "    train_vector = my_vector.copy()\n",
    "    if test:\n",
    "        train_vector, test_vector = split_vector(train_vector)\n",
    "    else:\n",
    "        test_vector = train_vector\n",
    "    \n",
    "    # Sử dụng getKnnVector cải tiến với adaptive K\n",
    "    vector = getKnnVector(train_vector, k=k, use_adaptive_k=use_adaptive_k)\n",
    "    \n",
    "    rcm_game_id = []\n",
    "    for i in range(len(vector)):\n",
    "        if vector[i] > 0:\n",
    "            rcm_game_id.append((games_id_reviews[i], vector[i]))\n",
    "    \n",
    "    # CẢI TIẾN: Áp dụng popularity penalty (TẮT MẶC ĐỊNH - chỉ bật nếu cần)\n",
    "    # Popularity penalty có thể làm giảm relevance scores và chất lượng recommendations\n",
    "    if apply_popularity_penalty:\n",
    "        # Tạo metadata dict từ games_details\n",
    "        games_metadata_dict = {}\n",
    "        for _, row in games_details.iterrows():\n",
    "            games_metadata_dict[row['app_id']] = {\n",
    "                'user_reviews': row.get('user_reviews', 0)\n",
    "            }\n",
    "        \n",
    "        rcm_game_id = knn_imp.apply_popularity_penalty(\n",
    "            rcm_game_id, \n",
    "            games_metadata_dict, \n",
    "            penalty_factor=popularity_penalty_factor\n",
    "        )\n",
    "        print(f\"Applied popularity penalty (factor={popularity_penalty_factor})\")\n",
    "    \n",
    "    rcm_game_id = sorted(rcm_game_id, key=lambda x: -x[1])\n",
    "    \n",
    "    if test:\n",
    "        measure = getMesure(rcm_game_id, test_vector)\n",
    "        return rcm_game_id, measure\n",
    "    \n",
    "    return rcm_game_id, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendation(rcm, test = False):\n",
    "    if test:\n",
    "        recommended_game_ids = [game[0] for game in rcm]\n",
    "    else:\n",
    "        recommended_game_ids = [game[0] for game in rcm if game[0] not in not_played_games_id]\n",
    "    print(recommended_game_ids)\n",
    "    games_details = pd.read_csv(\"final_games.csv\")\n",
    "    recommended_game_details = games_details[(games_details['app_id'].isin(recommended_game_ids))].copy()\n",
    "    relevance_df = pd.DataFrame(rcm, columns=['app_id', 'relevance'])\n",
    "    recommended_game_details_with_relevance = pd.merge(recommended_game_details, relevance_df, on='app_id')\n",
    "    recommended_game_details_sorted = recommended_game_details_with_relevance.sort_values(by='relevance', ascending=False)\n",
    "    recommended_game_details_wish = recommended_game_details_sorted[recommended_game_details_sorted['app_id'].isin(interested_games_id)]\n",
    "    return recommended_game_details_sorted[['sort_rank', 'title', 'date_release', 'relevance', 'positive_ratio', 'user_reviews']],recommended_game_details_wish[['sort_rank', 'title', 'date_release', 'relevance', 'positive_ratio', 'user_reviews']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CẢI TIẾN: Sử dụng với cài đặt an toàn (giữ gần code gốc)\n",
    "# TẮT adaptive K và popularity penalty để đảm bảo relevance scores đúng\n",
    "rcm, measure = getRecommendedGameId(\n",
    "    k=30,  # Dùng K cố định như code gốc (có thể thử adaptive K sau)\n",
    "    test=False,\n",
    "    use_adaptive_k=False,  # TẮT adaptive K để giữ như code gốc\n",
    "    apply_popularity_penalty=False,  # TẮT popularity penalty - giữ nguyên relevance scores\n",
    "    popularity_penalty_factor=0.05\n",
    ")\n",
    "print(f\"\\nTotal recommendations: {len(rcm)}\")\n",
    "print(\"\\nTop 10 recommendations:\")\n",
    "for i, (game_id, relevance) in enumerate(rcm[:10]):\n",
    "    print(f\"{i+1}. Game ID: {game_id}, Relevance: {relevance:.4f}\")\n",
    "if measure is not None:\n",
    "    print(f\"\\nMetrics: Accuracy={measure[0]:.2f}%, Precision={measure[1]:.2f}%, Recall={measure[2]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CẢI TIẾN: Tính diversity metrics để đánh giá chất lượng recommendations\n",
    "if len(rcm) > 0:\n",
    "    # Tạo metadata dict cho diversity calculation\n",
    "    games_metadata_dict = {}\n",
    "    for _, row in games_details.iterrows():\n",
    "        games_metadata_dict[row['app_id']] = {\n",
    "            'genres': row.get('genres', '') if 'genres' in row else ''\n",
    "        }\n",
    "    \n",
    "    # Tính diversity (nếu có genre data)\n",
    "    try:\n",
    "        diversity = knn_imp.calculate_diversity(rcm, games_metadata_dict, top_k=10)\n",
    "        print(f\"\\nDiversity (top 10): {diversity:.3f} (càng cao càng đa dạng)\")\n",
    "    except:\n",
    "        print(\"\\nDiversity calculation skipped (no genre data)\")\n",
    "    \n",
    "    # Tính coverage\n",
    "    coverage = knn_imp.calculate_coverage(rcm, games_id_reviews, top_k=10)\n",
    "    print(f\"Coverage (top 10): {coverage:.6f} (tỷ lệ games được recommend)\")\n",
    "else:\n",
    "    print(\"No recommendations to analyze\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation, recommendation_wish = getRecommendation(rcm, test=False)\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recommendation_wish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation.to_csv('rcm_games.csv', index=False)\n",
    "recommendation_wish.to_csv(\"rcm_wish.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = time.time()- start\n",
    "print(\"Time:\",tim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "\n",
    "class DataFrameViewer:\n",
    "    def __init__(self, root, dataframe):\n",
    "        self.root = root\n",
    "        self.root.title('Recommended Games (' + str(round(tim,1)) + 's)')\n",
    "\n",
    "        # Create scrolled text widget with monospaced font\n",
    "        self.txt = scrolledtext.ScrolledText(self.root, width=100, height=20, wrap=tk.NONE, font=(\"Courier\", 10))\n",
    "        self.txt.pack(expand=True, fill=tk.BOTH)\n",
    "\n",
    "        # Format DataFrame to string with proper alignment and fixed column widths\n",
    "        try:\n",
    "            df_str = self.format_dataframe(dataframe)\n",
    "            self.txt.insert(tk.END, df_str)\n",
    "        except AttributeError:\n",
    "            self.txt.insert(tk.END, \"Invalid DataFrame\")\n",
    "\n",
    "        # Disable editing\n",
    "        self.txt.configure(state='disabled')\n",
    "\n",
    "    def format_dataframe(self, dataframe):\n",
    "        # Define column widths\n",
    "        col_widths = {\n",
    "            'Rank':10,\n",
    "            'sort_rank': 10,\n",
    "            'title': 60,\n",
    "            'date_release': 20,\n",
    "            'relevance' : 20,\n",
    "            'positive_ratio': 20,\n",
    "            'user_reviews':10\n",
    "        }\n",
    "\n",
    "        # Create formatted string\n",
    "        header = \"\".join([f\"{col:{col_widths[col]}}\" for col in dataframe.columns]) + \"\\n\"\n",
    "        rows = \"\\n\".join(\n",
    "            \"\".join([f\"{str(value):{col_widths[col]}}\" for col, value in row.items()])\n",
    "            for _, row in dataframe.iterrows()\n",
    "        )\n",
    "\n",
    "        return header + rows\n",
    "\n",
    "def main(recommendation):\n",
    "    recommendation['Rank'] = range(1, len(recommendation) + 1)\n",
    "\n",
    "    # Insert the 'rank' column at the first position\n",
    "    recommendation.insert(0, 'Rank', recommendation.pop('Rank'))\n",
    "    root = tk.Tk()\n",
    "    app = DataFrameViewer(root, recommendation)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(recommendation_wish)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
